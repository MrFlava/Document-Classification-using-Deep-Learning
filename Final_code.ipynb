{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "#from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD,RMSprop,adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-Note\n",
      "\n",
      "Loaded the images of dataset-Report\n",
      "\n",
      "Loaded the images of dataset-Scientific\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = os.getcwd()\n",
    "# Define data path\n",
    "data_path = PATH + '/data'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "num_channel=1\n",
    "num_epoch=10\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 3\n",
    "\n",
    "img_data_list=[]\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "        \n",
    "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    for img in img_list:\n",
    "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img)\n",
    "        if input_img is not None:\n",
    "                    \t \t#print input_img\n",
    "            input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY) \n",
    "            input_img_resize=cv2.resize(input_img,(299,299))\n",
    "            img_data_list.append(input_img_resize)\n",
    "               \n",
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "if num_channel==1:\n",
    "\tif K.image_dim_ordering()=='th':\n",
    "\t\timg_data= np.expand_dims(img_data, axis=1) \n",
    "\t\tprint (img_data.shape)\n",
    "\telse:\n",
    "\t\timg_data= np.expand_dims(img_data, axis=4) \n",
    "\t\t\n",
    "else:\n",
    "\tif K.image_dim_ordering()=='th':\n",
    "\t\timg_data=np.rollaxis(img_data,3,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning Labels\n",
    "USE_SKLEARN_PREPROCESSING=False\n",
    "\n",
    "if USE_SKLEARN_PREPROCESSING:\n",
    "\t# using sklearn for preprocessing\n",
    "\tfrom sklearn import preprocessing\n",
    "\t\n",
    "\tdef image_to_feature_vector(image, size=(128, 128)):\n",
    "\t\t# resize the image to a fixed size, then flatten the image into\n",
    "\t\t# a list of raw pixel intensities\n",
    "\t\treturn cv2.resize(image, size).flatten()\n",
    "\t\n",
    "\timg_data_list=[]\n",
    "\tfor dataset in data_dir_list:\n",
    "\t\timg_list=os.listdir(data_path+'/'+ dataset)\n",
    "\t\tprint ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "\t\tfor img in img_list:\n",
    "\t\t\tinput_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "\t\t\tinput_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "\t\t\tinput_img_flatten=image_to_feature_vector(input_img,(128,128))\n",
    "\t\t\timg_data_list.append(input_img_flatten)\n",
    "\t\n",
    "\timg_data = np.array(img_data_list)\n",
    "\timg_data = img_data.astype('float32')\n",
    "\tprint (img_data.shape)\n",
    "\timg_data_scaled = preprocessing.scale(img_data)\n",
    "\tprint (img_data_scaled.shape)\n",
    "\t\n",
    "\tprint (np.mean(img_data_scaled))\n",
    "\tprint (np.std(img_data_scaled))\n",
    "\t\n",
    "\tprint (img_data_scaled.mean(axis=0))\n",
    "\tprint (img_data_scaled.std(axis=0))\n",
    "\t\n",
    "\tif K.image_dim_ordering()=='th':\n",
    "\t\timg_data_scaled=img_data_scaled.reshape(img_data.shape[0],num_channel,img_rows,img_cols)\n",
    "\t\tprint (img_data_scaled.shape)\n",
    "\t\t\n",
    "\telse:\n",
    "\t\timg_data_scaled=img_data_scaled.reshape(img_data.shape[0],img_rows,img_cols,num_channel)\n",
    "\t\tprint (img_data_scaled.shape)\n",
    "\t\n",
    "\t\n",
    "\tif K.image_dim_ordering()=='th':\n",
    "\t\timg_data_scaled=img_data_scaled.reshape(img_data.shape[0],num_channel,img_rows,img_cols)\n",
    "\t\tprint (img_data_scaled.shape)\n",
    "\t\t\n",
    "\telse:\n",
    "\t\timg_data_scaled=img_data_scaled.reshape(img_data.shape[0],img_rows,img_cols,num_channel)\n",
    "\t\tprint (img_data_scaled.shape)\n",
    "\n",
    "if USE_SKLEARN_PREPROCESSING:\n",
    "\timg_data=img_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "\n",
    "num_of_samples = img_data.shape[0]\n",
    "labels = np.ones((num_of_samples,),dtype='int64')\n",
    "\n",
    "labels[0:202]=0\n",
    "labels[202:464]=1\n",
    "labels[464:]=2\n",
    "\n",
    "names = ['Note','Scientific','Report']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class labels to on-hot encoding\n",
    "Y = np_utils.to_categorical(labels, num_classes)\n",
    "\n",
    "#Shuffle the dataset\n",
    "x,y = shuffle(img_data,Y, random_state=2)\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
    "\n",
    "input_shape=img_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 299, 299, 32)      320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 299, 299, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 297, 297, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 297, 297, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 146, 146, 64)      18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 146, 146, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341056)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                21827648  \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 195       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 21,855,907\n",
      "Trainable params: 21,855,907\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Defining Model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3),padding='same',input_shape=(299,299,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Convolution2D(64, 3, 3))\n",
    "#model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=[\"accuracy\"])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=[\"accuracy\"])\n",
    "\n",
    "# Viewing model_configuration\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 581 samples, validate on 146 samples\n",
      "Epoch 1/10\n",
      "581/581 [==============================] - 209s 360ms/step - loss: 3.5945 - acc: 0.4182 - val_loss: 1.0481 - val_acc: 0.4726\n",
      "Epoch 2/10\n",
      "581/581 [==============================] - 207s 356ms/step - loss: 0.9539 - acc: 0.5404 - val_loss: 0.8784 - val_acc: 0.5822\n",
      "Epoch 3/10\n",
      "581/581 [==============================] - 209s 360ms/step - loss: 0.7875 - acc: 0.6506 - val_loss: 0.9533 - val_acc: 0.4658\n",
      "Epoch 4/10\n",
      "581/581 [==============================] - 206s 355ms/step - loss: 0.7067 - acc: 0.7212 - val_loss: 0.6038 - val_acc: 0.7260\n",
      "Epoch 5/10\n",
      "581/581 [==============================] - 206s 355ms/step - loss: 0.6131 - acc: 0.7556 - val_loss: 0.6486 - val_acc: 0.7055\n",
      "Epoch 6/10\n",
      "581/581 [==============================] - 207s 357ms/step - loss: 0.5138 - acc: 0.8210 - val_loss: 0.6457 - val_acc: 0.7192\n",
      "Epoch 7/10\n",
      "581/581 [==============================] - 207s 356ms/step - loss: 0.3799 - acc: 0.8623 - val_loss: 0.6923 - val_acc: 0.7123\n",
      "Epoch 8/10\n",
      "581/581 [==============================] - 206s 354ms/step - loss: 0.3264 - acc: 0.8761 - val_loss: 0.6510 - val_acc: 0.7192\n",
      "Epoch 9/10\n",
      "581/581 [==============================] - 206s 355ms/step - loss: 0.2118 - acc: 0.9260 - val_loss: 0.6974 - val_acc: 0.7466\n",
      "Epoch 10/10\n",
      "581/581 [==============================] - 206s 354ms/step - loss: 0.1653 - acc: 0.9363 - val_loss: 0.7295 - val_acc: 0.7123\n",
      "Saved model to disk\n",
      "Test Loss: 0.7295438181864072\n",
      "Test accuracy: 0.7123287663067857\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      class 0(Note)       0.80      0.80      0.80        45\n",
      "class 1(scientific)       0.84      0.56      0.68        48\n",
      "    class 2(report)       0.59      0.77      0.67        53\n",
      "\n",
      "        avg / total       0.74      0.71      0.71       146\n",
      "\n",
      "[[36  1  8]\n",
      " [ 1 27 20]\n",
      " [ 8  4 41]]\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "hist = model.fit(X_train, y_train, batch_size=16, epochs=num_epoch, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "# Evaluating the model \n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "target_names = ['class 0(Note)', 'class 1(scientific)','class 2(report)']\n",
    "\n",
    "print(classification_report(np.argmax(y_test,axis=1), y_pred,target_names=target_names))\n",
    "\n",
    "print(confusion_matrix(np.argmax(y_test,axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With 10 epochs, we get the Training accuracy=93.63 \n",
    "# We can tune the model with the variation of number of epochs and increasing the data.\n",
    "# Large batch size may converge faster and give better results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
